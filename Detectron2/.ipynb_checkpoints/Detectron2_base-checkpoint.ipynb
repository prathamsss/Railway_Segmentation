{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7353176c-60e3-47b0-857f-1358c9ec8553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20b2583-01d8-4179-9247-de6fcd31ae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Python 3.7.10\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c9886a-c3f9-4017-b853-aeb73f42c16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.7.1', '11.0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__, torch.version.cuda , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a700420-6f70-4c78-804f-221b7e55bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install detectron2 -f \\\n",
    " # https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a86f74-6535-4164-969f-a407892557d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1 True\n"
     ]
    }
   ],
   "source": [
    "# check pytorch installation: \n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "assert torch.__version__.startswith(\"1.7\")   # please manually install torch 1.9 if Colab changes its default version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea2d816a-aa07-4e8e-9e54-bb52dfe58cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.evaluation import inference_context\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "import detectron2.utils.comm as comm\n",
    "import time\n",
    "import datetime\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "import copy\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.data import build_detection_train_loader\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b1ac79-4852-4cd8-bc25-adbe6df4d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.zeros([1],device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f65106a2-a9ad-40d1-a1f1-7af1e1b37cab",
   "metadata": {},
   "outputs": [],
   "source": [
    " from detectron2.data.datasets import register_coco_instances\n",
    "    \n",
    "def data_registration(train_dir,train_name,valid_dir,valid_name):\n",
    "    path_train_coco = os.path.join(train_dir,\"Train.json\")\n",
    "    path_train_imgs = os.path.join(train_dir, \"Images\")\n",
    "    path_train_masks = os.path.join(train_dir, \"Masks\")\n",
    "    \n",
    "    path_valid_coco= os.path.join(valid_dir,\"Valid.json\")\n",
    "    path_valid_imgs =  os.path.join(valid_dir, \"Images\")\n",
    "    path_valid_masks = os.path.join(valid_dir, \"Masks\")\n",
    "\n",
    "      \n",
    "    print(\"Totoal Train Images in folder => \", len(os.listdir(path_train_imgs)))\n",
    "    print(\"Totoal Train Mask in folder => \", len(os.listdir(path_train_masks)))\n",
    "    print('\\n')\n",
    "\n",
    "    print(\"Totoal Valid Images  in folder =>\", len(os.listdir(path_valid_imgs)))\n",
    "    print(\"Totoal Valid Mask  in folder => \", len(os.listdir(path_valid_masks)))\n",
    "    \n",
    "    try:   \n",
    "        register_coco_instances(train_name, {}, path_train_coco, path_train_imgs)\n",
    "        register_coco_instances(valid_name, {}, path_valid_coco, path_valid_imgs)\n",
    "    except AssertionError:\n",
    "        print(\"\\n Data set Already registered! Change string if want to re-register!\")\n",
    "    \n",
    "    train_data=detectron2.data.datasets.load_coco_json(path_train_coco, path_train_imgs, dataset_name=train_name, extra_annotation_keys=None)\n",
    "    valid_data=detectron2.data.datasets.load_coco_json(path_valid_coco, path_valid_imgs, dataset_name=valid_name, extra_annotation_keys=None)\n",
    " \n",
    "    meta_train = MetadataCatalog.get(train_name).set(thing_classes=[\"Rail_road\"])\n",
    "    meta_valid = MetadataCatalog.get(valid_name).set(thing_classes=[\"Rail_road\"])\n",
    "    \n",
    "    print(\"No of Train = \",len(train_data))\n",
    "    print(\"No of Valid = \",len(valid_data))\n",
    "    \n",
    "    return train_data,meta_train, valid_data,meta_valid    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34bcd50c-4901-45cf-986c-d163d7512d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d58b088d-2fea-4f15-a760-7feaabd3099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totoal Train Images in folder =>  1397\n",
      "Totoal Train Mask in folder =>  1397\n",
      "\n",
      "\n",
      "Totoal Valid Images  in folder => 501\n",
      "Totoal Valid Mask  in folder =>  501\n",
      "\n",
      " Data set Already registered! Change string if want to re-register!\n",
      "\u001b[32m[10/06 09:27:00 d2.data.datasets.coco]: \u001b[0mLoaded 1397 images in COCO format from Data/Train/Train.json\n",
      "\u001b[32m[10/06 09:27:00 d2.data.datasets.coco]: \u001b[0mLoaded 501 images in COCO format from Data/Valid/Valid.json\n",
      "No of Train =  1397\n",
      "No of Valid =  501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "namespace(name='Valid',\n",
       "          json_file='Data/Valid/Valid.json',\n",
       "          image_root='Data/Valid/Images',\n",
       "          evaluator_type='coco',\n",
       "          thing_classes=['Rail_road'],\n",
       "          thing_dataset_id_to_contiguous_id={1: 0})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = \"Data/Train\"\n",
    "valid_dir = \"Data/Valid\"\n",
    "train_name = \"Train\"\n",
    "valid_name = \"Valid\"\n",
    "\n",
    "train_data,meta_train, valid_data,meta_valid     =  data_registration(train_dir,train_name,valid_dir,valid_name)\n",
    "meta_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "17625a41-f38d-4d8d-b653-4e0035699c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve visualisation issue, remove list appending \n",
    "%matplotlib inline\n",
    "from detectron2.data import DatasetCatalog\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_data(dataset_name,no_of_display_imgs_):\n",
    "    \n",
    "    dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "    \n",
    "    for d in random.sample(dataset_dicts, no_of_display_imgs_):\n",
    "        img = cv2.imread(d['file_name'])\n",
    "        print(d['file_name'])\n",
    "        visualizer = Visualizer(img[:, :, ::-1], metadata=meta_train, scale=0.5)\n",
    "        out = visualizer.draw_dataset_dict(d)\n",
    "        img = Image.fromarray(out.get_image()[:, :, ::-1], 'RGB')\n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c385e7c-c154-487e-8f2f-b943cab256e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(train_name,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a3a08e4-f8ba-43b0-8a49-69436cac3b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/06 10:29:17 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/06 10:29:17 d2.data.datasets.coco]: \u001b[0mLoaded 1397 images in COCO format from Data/Train/Train.json\n",
      "\u001b[32m[10/06 10:29:17 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1397 images left.\n",
      "\u001b[32m[10/06 10:29:17 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "| Rail_road  | 1397         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/06 10:29:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[10/06 10:29:17 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/06 10:29:17 d2.data.common]: \u001b[0mSerializing 1397 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/06 10:29:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.70 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_f10217.pkl: 178MB [00:15, 11.6MB/s]                                                                            \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/06 10:29:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/detectron2/structures/masks.py:363: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/detectron2/structures/masks.py:363: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/detectron2/structures/masks.py:363: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/detectron2/structures/masks.py:363: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/06 10:30:21 d2.utils.events]: \u001b[0m eta: 0:38:34  iter: 19  total_loss: 1.572  loss_cls: 0.7018  loss_box_reg: 0.1078  loss_mask: 0.6893  loss_rpn_cls: 0.05939  loss_rpn_loc: 0.006028  time: 0.9593  data_time: 0.0176  lr: 3.2349e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:30:40 d2.utils.events]: \u001b[0m eta: 0:38:20  iter: 39  total_loss: 1.212  loss_cls: 0.3247  loss_box_reg: 0.1442  loss_mask: 0.659  loss_rpn_cls: 0.04684  loss_rpn_loc: 0.00529  time: 0.9620  data_time: 0.0062  lr: 6.377e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:31:01 d2.utils.events]: \u001b[0m eta: 0:38:31  iter: 59  total_loss: 1.121  loss_cls: 0.2382  loss_box_reg: 0.2777  loss_mask: 0.5797  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.004241  time: 0.9805  data_time: 0.0062  lr: 9.519e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:31:22 d2.utils.events]: \u001b[0m eta: 0:38:44  iter: 79  total_loss: 0.9935  loss_cls: 0.2046  loss_box_reg: 0.3059  loss_mask: 0.4691  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.005094  time: 0.9975  data_time: 0.0063  lr: 0.00012661  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:31:43 d2.utils.events]: \u001b[0m eta: 0:39:23  iter: 99  total_loss: 0.9965  loss_cls: 0.1913  loss_box_reg: 0.4525  loss_mask: 0.3292  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.004027  time: 1.0123  data_time: 0.0061  lr: 0.00015803  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:32:04 d2.utils.events]: \u001b[0m eta: 0:39:18  iter: 119  total_loss: 0.8268  loss_cls: 0.1369  loss_box_reg: 0.4264  loss_mask: 0.2218  loss_rpn_cls: 0.01046  loss_rpn_loc: 0.0052  time: 1.0205  data_time: 0.0062  lr: 0.00018945  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:32:26 d2.utils.events]: \u001b[0m eta: 0:39:22  iter: 139  total_loss: 0.7172  loss_cls: 0.115  loss_box_reg: 0.4723  loss_mask: 0.1414  loss_rpn_cls: 0.008592  loss_rpn_loc: 0.003932  time: 1.0285  data_time: 0.0064  lr: 0.00022087  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:32:47 d2.utils.events]: \u001b[0m eta: 0:39:05  iter: 159  total_loss: 0.6469  loss_cls: 0.09438  loss_box_reg: 0.3987  loss_mask: 0.1381  loss_rpn_cls: 0.005013  loss_rpn_loc: 0.004388  time: 1.0321  data_time: 0.0062  lr: 0.00025229  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:33:08 d2.utils.events]: \u001b[0m eta: 0:39:00  iter: 179  total_loss: 0.5424  loss_cls: 0.09944  loss_box_reg: 0.2889  loss_mask: 0.1285  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.005285  time: 1.0363  data_time: 0.0059  lr: 0.00028371  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:33:30 d2.utils.events]: \u001b[0m eta: 0:38:53  iter: 199  total_loss: 0.472  loss_cls: 0.08729  loss_box_reg: 0.2195  loss_mask: 0.1165  loss_rpn_cls: 0.004893  loss_rpn_loc: 0.003556  time: 1.0400  data_time: 0.0060  lr: 0.00031513  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:33:51 d2.utils.events]: \u001b[0m eta: 0:38:39  iter: 219  total_loss: 0.4259  loss_cls: 0.06598  loss_box_reg: 0.1927  loss_mask: 0.1355  loss_rpn_cls: 0.004649  loss_rpn_loc: 0.004301  time: 1.0407  data_time: 0.0060  lr: 0.00034655  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:34:12 d2.utils.events]: \u001b[0m eta: 0:38:26  iter: 239  total_loss: 0.349  loss_cls: 0.062  loss_box_reg: 0.1898  loss_mask: 0.08288  loss_rpn_cls: 0.001826  loss_rpn_loc: 0.003002  time: 1.0439  data_time: 0.0065  lr: 0.00037797  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:34:34 d2.utils.events]: \u001b[0m eta: 0:38:08  iter: 259  total_loss: 0.4078  loss_cls: 0.07639  loss_box_reg: 0.1885  loss_mask: 0.09862  loss_rpn_cls: 0.00329  loss_rpn_loc: 0.003445  time: 1.0457  data_time: 0.0061  lr: 0.0004094  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:34:56 d2.utils.events]: \u001b[0m eta: 0:37:50  iter: 279  total_loss: 0.4314  loss_cls: 0.08831  loss_box_reg: 0.2235  loss_mask: 0.1007  loss_rpn_cls: 0.004401  loss_rpn_loc: 0.003441  time: 1.0489  data_time: 0.0065  lr: 0.00044082  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:35:17 d2.utils.events]: \u001b[0m eta: 0:37:29  iter: 299  total_loss: 0.3702  loss_cls: 0.06697  loss_box_reg: 0.1853  loss_mask: 0.08916  loss_rpn_cls: 0.003454  loss_rpn_loc: 0.003432  time: 1.0494  data_time: 0.0065  lr: 0.00047224  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:35:38 d2.utils.events]: \u001b[0m eta: 0:37:09  iter: 319  total_loss: 0.3324  loss_cls: 0.06258  loss_box_reg: 0.1883  loss_mask: 0.09243  loss_rpn_cls: 0.002431  loss_rpn_loc: 0.002664  time: 1.0502  data_time: 0.0059  lr: 0.00050366  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:35:59 d2.utils.events]: \u001b[0m eta: 0:36:49  iter: 339  total_loss: 0.352  loss_cls: 0.06651  loss_box_reg: 0.1857  loss_mask: 0.08772  loss_rpn_cls: 0.001883  loss_rpn_loc: 0.003386  time: 1.0511  data_time: 0.0063  lr: 0.00053508  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:36:21 d2.utils.events]: \u001b[0m eta: 0:36:30  iter: 359  total_loss: 0.4025  loss_cls: 0.07814  loss_box_reg: 0.2032  loss_mask: 0.1052  loss_rpn_cls: 0.001111  loss_rpn_loc: 0.003261  time: 1.0524  data_time: 0.0062  lr: 0.0005665  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:36:42 d2.utils.events]: \u001b[0m eta: 0:36:10  iter: 379  total_loss: 0.4497  loss_cls: 0.09372  loss_box_reg: 0.2236  loss_mask: 0.08899  loss_rpn_cls: 0.00226  loss_rpn_loc: 0.004166  time: 1.0541  data_time: 0.0064  lr: 0.00059792  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:37:04 d2.data.datasets.coco]: \u001b[0mLoaded 501 images in COCO format from Data/Valid/Valid.json\n",
      "\u001b[32m[10/06 10:37:04 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "| Rail_road  | 500          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/06 10:37:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/06 10:37:04 d2.data.common]: \u001b[0mSerializing 501 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/06 10:37:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.25 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/06 10:37:04 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[10/06 10:37:04 d2.utils.events]: \u001b[0m eta: 0:35:51  iter: 399  total_loss: 0.3632  loss_cls: 0.07875  loss_box_reg: 0.2012  loss_mask: 0.08382  loss_rpn_cls: 0.002083  loss_rpn_loc: 0.002636  time: 1.0548  data_time: 0.0064  lr: 0.00062934  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:37:25 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 419  total_loss: 0.3294  loss_cls: 0.05968  loss_box_reg: 0.1856  loss_mask: 0.06249  loss_rpn_cls: 0.001941  loss_rpn_loc: 0.002561  time: 1.0558  data_time: 0.0061  lr: 0.00066076  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:37:47 d2.utils.events]: \u001b[0m eta: 0:35:11  iter: 439  total_loss: 0.329  loss_cls: 0.0643  loss_box_reg: 0.1848  loss_mask: 0.0735  loss_rpn_cls: 0.002518  loss_rpn_loc: 0.002382  time: 1.0563  data_time: 0.0060  lr: 0.00069218  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:38:08 d2.utils.events]: \u001b[0m eta: 0:34:52  iter: 459  total_loss: 0.3405  loss_cls: 0.06973  loss_box_reg: 0.1695  loss_mask: 0.08278  loss_rpn_cls: 0.0008409  loss_rpn_loc: 0.002208  time: 1.0574  data_time: 0.0062  lr: 0.0007236  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:38:30 d2.utils.events]: \u001b[0m eta: 0:34:31  iter: 479  total_loss: 0.3434  loss_cls: 0.05898  loss_box_reg: 0.1715  loss_mask: 0.08451  loss_rpn_cls: 0.002027  loss_rpn_loc: 0.002578  time: 1.0579  data_time: 0.0063  lr: 0.00075502  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:38:51 d2.utils.events]: \u001b[0m eta: 0:34:10  iter: 499  total_loss: 0.3412  loss_cls: 0.06685  loss_box_reg: 0.1768  loss_mask: 0.1076  loss_rpn_cls: 0.001444  loss_rpn_loc: 0.002381  time: 1.0584  data_time: 0.0064  lr: 0.00078644  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:39:13 d2.utils.events]: \u001b[0m eta: 0:33:51  iter: 519  total_loss: 0.3112  loss_cls: 0.05082  loss_box_reg: 0.1718  loss_mask: 0.06539  loss_rpn_cls: 0.001038  loss_rpn_loc: 0.002587  time: 1.0593  data_time: 0.0063  lr: 0.00081786  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:39:34 d2.utils.events]: \u001b[0m eta: 0:33:30  iter: 539  total_loss: 0.2861  loss_cls: 0.04778  loss_box_reg: 0.1492  loss_mask: 0.05544  loss_rpn_cls: 0.001527  loss_rpn_loc: 0.00276  time: 1.0593  data_time: 0.0061  lr: 0.00084928  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:39:56 d2.utils.events]: \u001b[0m eta: 0:33:09  iter: 559  total_loss: 0.307  loss_cls: 0.0609  loss_box_reg: 0.1666  loss_mask: 0.06141  loss_rpn_cls: 0.0008961  loss_rpn_loc: 0.002646  time: 1.0601  data_time: 0.0061  lr: 0.0008807  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:40:17 d2.utils.events]: \u001b[0m eta: 0:32:48  iter: 579  total_loss: 0.405  loss_cls: 0.07749  loss_box_reg: 0.2035  loss_mask: 0.1071  loss_rpn_cls: 0.001435  loss_rpn_loc: 0.00297  time: 1.0603  data_time: 0.0059  lr: 0.00091212  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:40:39 d2.utils.events]: \u001b[0m eta: 0:32:28  iter: 599  total_loss: 0.2718  loss_cls: 0.05237  loss_box_reg: 0.1523  loss_mask: 0.06796  loss_rpn_cls: 0.0005446  loss_rpn_loc: 0.002305  time: 1.0611  data_time: 0.0058  lr: 0.00094354  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:41:00 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 619  total_loss: 0.3633  loss_cls: 0.05617  loss_box_reg: 0.1741  loss_mask: 0.09211  loss_rpn_cls: 0.001077  loss_rpn_loc: 0.002465  time: 1.0618  data_time: 0.0060  lr: 0.00097496  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:41:22 d2.utils.events]: \u001b[0m eta: 0:31:45  iter: 639  total_loss: 0.2711  loss_cls: 0.05125  loss_box_reg: 0.1631  loss_mask: 0.05657  loss_rpn_cls: 0.0005101  loss_rpn_loc: 0.002445  time: 1.0625  data_time: 0.0064  lr: 0.0010064  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:41:44 d2.utils.events]: \u001b[0m eta: 0:31:24  iter: 659  total_loss: 0.3521  loss_cls: 0.06519  loss_box_reg: 0.1877  loss_mask: 0.07064  loss_rpn_cls: 0.002991  loss_rpn_loc: 0.002472  time: 1.0632  data_time: 0.0061  lr: 0.0010378  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:42:05 d2.utils.events]: \u001b[0m eta: 0:31:04  iter: 679  total_loss: 0.3355  loss_cls: 0.06538  loss_box_reg: 0.176  loss_mask: 0.07177  loss_rpn_cls: 0.0005514  loss_rpn_loc: 0.002472  time: 1.0637  data_time: 0.0068  lr: 0.0010692  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:42:27 d2.utils.events]: \u001b[0m eta: 0:30:42  iter: 699  total_loss: 0.353  loss_cls: 0.07374  loss_box_reg: 0.1833  loss_mask: 0.09339  loss_rpn_cls: 0.000711  loss_rpn_loc: 0.002421  time: 1.0643  data_time: 0.0064  lr: 0.0011006  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:42:48 d2.utils.events]: \u001b[0m eta: 0:30:21  iter: 719  total_loss: 0.3075  loss_cls: 0.0691  loss_box_reg: 0.1654  loss_mask: 0.06754  loss_rpn_cls: 0.000481  loss_rpn_loc: 0.002317  time: 1.0643  data_time: 0.0067  lr: 0.0011321  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:43:10 d2.utils.events]: \u001b[0m eta: 0:29:59  iter: 739  total_loss: 0.2758  loss_cls: 0.05349  loss_box_reg: 0.1602  loss_mask: 0.06367  loss_rpn_cls: 0.0004618  loss_rpn_loc: 0.002294  time: 1.0647  data_time: 0.0065  lr: 0.0011635  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:43:32 d2.utils.events]: \u001b[0m eta: 0:29:38  iter: 759  total_loss: 0.3555  loss_cls: 0.06696  loss_box_reg: 0.1614  loss_mask: 0.07567  loss_rpn_cls: 0.000569  loss_rpn_loc: 0.00245  time: 1.0651  data_time: 0.0061  lr: 0.0011949  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:43:53 d2.utils.events]: \u001b[0m eta: 0:29:16  iter: 779  total_loss: 0.3839  loss_cls: 0.07481  loss_box_reg: 0.2094  loss_mask: 0.07659  loss_rpn_cls: 0.0005223  loss_rpn_loc: 0.002654  time: 1.0651  data_time: 0.0064  lr: 0.0012263  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:44:14 d2.data.datasets.coco]: \u001b[0mLoaded 501 images in COCO format from Data/Valid/Valid.json\n",
      "\u001b[32m[10/06 10:44:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/06 10:44:14 d2.data.common]: \u001b[0mSerializing 501 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/06 10:44:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.25 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/06 10:44:14 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[10/06 10:44:14 d2.utils.events]: \u001b[0m eta: 0:28:55  iter: 799  total_loss: 0.2576  loss_cls: 0.04546  loss_box_reg: 0.1342  loss_mask: 0.05188  loss_rpn_cls: 0.0001962  loss_rpn_loc: 0.001996  time: 1.0653  data_time: 0.0062  lr: 0.0012577  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:44:36 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 819  total_loss: 0.333  loss_cls: 0.07395  loss_box_reg: 0.175  loss_mask: 0.07093  loss_rpn_cls: 0.0007287  loss_rpn_loc: 0.002251  time: 1.0653  data_time: 0.0062  lr: 0.0012892  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:44:57 d2.utils.events]: \u001b[0m eta: 0:28:12  iter: 839  total_loss: 0.401  loss_cls: 0.08721  loss_box_reg: 0.2062  loss_mask: 0.07848  loss_rpn_cls: 0.0007524  loss_rpn_loc: 0.00311  time: 1.0655  data_time: 0.0063  lr: 0.0013206  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:45:18 d2.utils.events]: \u001b[0m eta: 0:27:50  iter: 859  total_loss: 0.3361  loss_cls: 0.07477  loss_box_reg: 0.1663  loss_mask: 0.07649  loss_rpn_cls: 0.001338  loss_rpn_loc: 0.002117  time: 1.0654  data_time: 0.0064  lr: 0.001352  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:45:40 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 879  total_loss: 0.2988  loss_cls: 0.07253  loss_box_reg: 0.1697  loss_mask: 0.08533  loss_rpn_cls: 0.0009837  loss_rpn_loc: 0.002283  time: 1.0656  data_time: 0.0060  lr: 0.0013834  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:46:01 d2.utils.events]: \u001b[0m eta: 0:27:07  iter: 899  total_loss: 0.3595  loss_cls: 0.06677  loss_box_reg: 0.1709  loss_mask: 0.08388  loss_rpn_cls: 0.0009656  loss_rpn_loc: 0.002349  time: 1.0653  data_time: 0.0062  lr: 0.0014149  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:46:22 d2.utils.events]: \u001b[0m eta: 0:26:46  iter: 919  total_loss: 0.2928  loss_cls: 0.05447  loss_box_reg: 0.1831  loss_mask: 0.06169  loss_rpn_cls: 0.001161  loss_rpn_loc: 0.002772  time: 1.0653  data_time: 0.0061  lr: 0.0014463  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:46:44 d2.utils.events]: \u001b[0m eta: 0:26:24  iter: 939  total_loss: 0.2171  loss_cls: 0.04421  loss_box_reg: 0.1175  loss_mask: 0.05613  loss_rpn_cls: 0.00138  loss_rpn_loc: 0.002165  time: 1.0654  data_time: 0.0059  lr: 0.0014777  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:47:05 d2.utils.events]: \u001b[0m eta: 0:26:02  iter: 959  total_loss: 0.231  loss_cls: 0.05358  loss_box_reg: 0.1464  loss_mask: 0.04626  loss_rpn_cls: 0.0005652  loss_rpn_loc: 0.00238  time: 1.0655  data_time: 0.0060  lr: 0.0015091  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:47:27 d2.utils.events]: \u001b[0m eta: 0:25:41  iter: 979  total_loss: 0.3076  loss_cls: 0.048  loss_box_reg: 0.1801  loss_mask: 0.06708  loss_rpn_cls: 0.001248  loss_rpn_loc: 0.002517  time: 1.0658  data_time: 0.0062  lr: 0.0015405  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:47:48 d2.utils.events]: \u001b[0m eta: 0:25:19  iter: 999  total_loss: 0.2543  loss_cls: 0.05826  loss_box_reg: 0.1345  loss_mask: 0.05051  loss_rpn_cls: 0.002048  loss_rpn_loc: 0.002174  time: 1.0662  data_time: 0.0061  lr: 0.001572  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:48:09 d2.utils.events]: \u001b[0m eta: 0:24:58  iter: 1019  total_loss: 0.2488  loss_cls: 0.05322  loss_box_reg: 0.1371  loss_mask: 0.05319  loss_rpn_cls: 0.0006036  loss_rpn_loc: 0.00265  time: 1.0660  data_time: 0.0064  lr: 0.0015434  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:48:31 d2.utils.events]: \u001b[0m eta: 0:24:37  iter: 1039  total_loss: 0.2206  loss_cls: 0.03807  loss_box_reg: 0.1205  loss_mask: 0.05751  loss_rpn_cls: 0.0004439  loss_rpn_loc: 0.001863  time: 1.0662  data_time: 0.0060  lr: 0.0015115  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:48:53 d2.utils.events]: \u001b[0m eta: 0:24:16  iter: 1059  total_loss: 0.2507  loss_cls: 0.04827  loss_box_reg: 0.137  loss_mask: 0.06584  loss_rpn_cls: 0.0004079  loss_rpn_loc: 0.002264  time: 1.0665  data_time: 0.0066  lr: 0.0014794  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:49:14 d2.utils.events]: \u001b[0m eta: 0:23:54  iter: 1079  total_loss: 0.2797  loss_cls: 0.04904  loss_box_reg: 0.1521  loss_mask: 0.05716  loss_rpn_cls: 0.0005278  loss_rpn_loc: 0.002402  time: 1.0668  data_time: 0.0065  lr: 0.0014472  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:49:36 d2.utils.events]: \u001b[0m eta: 0:23:33  iter: 1099  total_loss: 0.3305  loss_cls: 0.07702  loss_box_reg: 0.173  loss_mask: 0.0727  loss_rpn_cls: 0.0006761  loss_rpn_loc: 0.002469  time: 1.0670  data_time: 0.0063  lr: 0.0014148  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:49:58 d2.utils.events]: \u001b[0m eta: 0:23:11  iter: 1119  total_loss: 0.2322  loss_cls: 0.04313  loss_box_reg: 0.1376  loss_mask: 0.05083  loss_rpn_cls: 0.0005945  loss_rpn_loc: 0.001661  time: 1.0673  data_time: 0.0065  lr: 0.0013823  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:50:19 d2.utils.events]: \u001b[0m eta: 0:22:50  iter: 1139  total_loss: 0.2629  loss_cls: 0.05079  loss_box_reg: 0.15  loss_mask: 0.06614  loss_rpn_cls: 0.0004839  loss_rpn_loc: 0.002062  time: 1.0675  data_time: 0.0063  lr: 0.0013497  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:50:41 d2.utils.events]: \u001b[0m eta: 0:22:28  iter: 1159  total_loss: 0.2317  loss_cls: 0.04757  loss_box_reg: 0.1328  loss_mask: 0.06692  loss_rpn_cls: 0.0006998  loss_rpn_loc: 0.002318  time: 1.0675  data_time: 0.0063  lr: 0.0013171  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:51:02 d2.utils.events]: \u001b[0m eta: 0:22:07  iter: 1179  total_loss: 0.2134  loss_cls: 0.05051  loss_box_reg: 0.1234  loss_mask: 0.04793  loss_rpn_cls: 0.0007141  loss_rpn_loc: 0.002058  time: 1.0677  data_time: 0.0064  lr: 0.0012844  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:51:24 d2.data.datasets.coco]: \u001b[0mLoaded 501 images in COCO format from Data/Valid/Valid.json\n",
      "\u001b[32m[10/06 10:51:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/06 10:51:24 d2.data.common]: \u001b[0mSerializing 501 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/06 10:51:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.25 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/06 10:51:24 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[10/06 10:51:24 d2.utils.events]: \u001b[0m eta: 0:21:45  iter: 1199  total_loss: 0.2701  loss_cls: 0.05875  loss_box_reg: 0.1484  loss_mask: 0.05575  loss_rpn_cls: 0.001198  loss_rpn_loc: 0.002361  time: 1.0682  data_time: 0.0062  lr: 0.0012516  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:51:46 d2.utils.events]: \u001b[0m eta: 0:21:24  iter: 1219  total_loss: 0.2416  loss_cls: 0.0505  loss_box_reg: 0.1493  loss_mask: 0.04937  loss_rpn_cls: 0.0007143  loss_rpn_loc: 0.001605  time: 1.0684  data_time: 0.0063  lr: 0.0012189  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:52:07 d2.utils.events]: \u001b[0m eta: 0:21:02  iter: 1239  total_loss: 0.2348  loss_cls: 0.04254  loss_box_reg: 0.133  loss_mask: 0.04609  loss_rpn_cls: 0.0002439  loss_rpn_loc: 0.001874  time: 1.0683  data_time: 0.0064  lr: 0.0011862  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:52:29 d2.utils.events]: \u001b[0m eta: 0:20:40  iter: 1259  total_loss: 0.2427  loss_cls: 0.05248  loss_box_reg: 0.137  loss_mask: 0.04667  loss_rpn_cls: 0.0004027  loss_rpn_loc: 0.002381  time: 1.0685  data_time: 0.0062  lr: 0.0011536  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:52:50 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 1279  total_loss: 0.2244  loss_cls: 0.04082  loss_box_reg: 0.1256  loss_mask: 0.04995  loss_rpn_cls: 0.0002774  loss_rpn_loc: 0.001789  time: 1.0686  data_time: 0.0065  lr: 0.001121  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:53:11 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 1299  total_loss: 0.247  loss_cls: 0.04826  loss_box_reg: 0.1345  loss_mask: 0.04885  loss_rpn_cls: 0.0006739  loss_rpn_loc: 0.001829  time: 1.0685  data_time: 0.0062  lr: 0.0010885  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:53:33 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 1319  total_loss: 0.3771  loss_cls: 0.06723  loss_box_reg: 0.184  loss_mask: 0.108  loss_rpn_cls: 0.0008574  loss_rpn_loc: 0.002314  time: 1.0687  data_time: 0.0064  lr: 0.0010561  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:53:55 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 1339  total_loss: 0.2534  loss_cls: 0.05405  loss_box_reg: 0.1459  loss_mask: 0.06196  loss_rpn_cls: 0.0003492  loss_rpn_loc: 0.002253  time: 1.0689  data_time: 0.0066  lr: 0.0010238  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:54:16 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 1359  total_loss: 0.2606  loss_cls: 0.04827  loss_box_reg: 0.1508  loss_mask: 0.05869  loss_rpn_cls: 0.0003819  loss_rpn_loc: 0.002027  time: 1.0691  data_time: 0.0064  lr: 0.00099171  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:54:38 d2.utils.events]: \u001b[0m eta: 0:18:30  iter: 1379  total_loss: 0.2908  loss_cls: 0.05528  loss_box_reg: 0.1453  loss_mask: 0.07273  loss_rpn_cls: 0.0007099  loss_rpn_loc: 0.00207  time: 1.0693  data_time: 0.0060  lr: 0.00095978  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:55:00 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 1399  total_loss: 0.2116  loss_cls: 0.04126  loss_box_reg: 0.1145  loss_mask: 0.04668  loss_rpn_cls: 0.0007512  loss_rpn_loc: 0.002206  time: 1.0695  data_time: 0.0062  lr: 0.00092806  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:55:21 d2.utils.events]: \u001b[0m eta: 0:17:47  iter: 1419  total_loss: 0.2139  loss_cls: 0.03863  loss_box_reg: 0.1261  loss_mask: 0.04503  loss_rpn_cls: 0.0007497  loss_rpn_loc: 0.001544  time: 1.0696  data_time: 0.0060  lr: 0.00089655  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:55:43 d2.utils.events]: \u001b[0m eta: 0:17:25  iter: 1439  total_loss: 0.2069  loss_cls: 0.03815  loss_box_reg: 0.111  loss_mask: 0.04352  loss_rpn_cls: 0.0002977  loss_rpn_loc: 0.001929  time: 1.0696  data_time: 0.0065  lr: 0.00086529  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:56:04 d2.utils.events]: \u001b[0m eta: 0:17:04  iter: 1459  total_loss: 0.1874  loss_cls: 0.03641  loss_box_reg: 0.1045  loss_mask: 0.04512  loss_rpn_cls: 0.0004725  loss_rpn_loc: 0.001838  time: 1.0699  data_time: 0.0065  lr: 0.00083428  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:56:26 d2.utils.events]: \u001b[0m eta: 0:16:42  iter: 1479  total_loss: 0.1915  loss_cls: 0.03288  loss_box_reg: 0.1126  loss_mask: 0.04341  loss_rpn_cls: 8.69e-05  loss_rpn_loc: 0.001586  time: 1.0700  data_time: 0.0059  lr: 0.00080357  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:56:48 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 1499  total_loss: 0.2307  loss_cls: 0.04672  loss_box_reg: 0.1308  loss_mask: 0.04616  loss_rpn_cls: 0.0003924  loss_rpn_loc: 0.001839  time: 1.0702  data_time: 0.0060  lr: 0.00077316  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:57:09 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 1519  total_loss: 0.194  loss_cls: 0.03947  loss_box_reg: 0.1021  loss_mask: 0.04135  loss_rpn_cls: 0.0004324  loss_rpn_loc: 0.001493  time: 1.0703  data_time: 0.0061  lr: 0.00074307  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:57:31 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 1539  total_loss: 0.2095  loss_cls: 0.03848  loss_box_reg: 0.1091  loss_mask: 0.0504  loss_rpn_cls: 0.0002139  loss_rpn_loc: 0.001779  time: 1.0703  data_time: 0.0061  lr: 0.00071334  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:57:52 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 1559  total_loss: 0.202  loss_cls: 0.03467  loss_box_reg: 0.1217  loss_mask: 0.04364  loss_rpn_cls: 0.0002897  loss_rpn_loc: 0.001862  time: 1.0704  data_time: 0.0064  lr: 0.00068397  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:58:14 d2.utils.events]: \u001b[0m eta: 0:14:53  iter: 1579  total_loss: 0.2177  loss_cls: 0.04459  loss_box_reg: 0.1321  loss_mask: 0.0444  loss_rpn_cls: 0.0001668  loss_rpn_loc: 0.002147  time: 1.0704  data_time: 0.0063  lr: 0.00065499  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:58:35 d2.data.datasets.coco]: \u001b[0mLoaded 501 images in COCO format from Data/Valid/Valid.json\n",
      "\u001b[32m[10/06 10:58:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/06 10:58:35 d2.data.common]: \u001b[0mSerializing 501 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/06 10:58:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.25 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/06 10:58:35 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[10/06 10:58:35 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 1599  total_loss: 0.2065  loss_cls: 0.04248  loss_box_reg: 0.1257  loss_mask: 0.04644  loss_rpn_cls: 0.0002799  loss_rpn_loc: 0.00206  time: 1.0706  data_time: 0.0063  lr: 0.00062642  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:58:57 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 1619  total_loss: 0.2571  loss_cls: 0.04802  loss_box_reg: 0.138  loss_mask: 0.07334  loss_rpn_cls: 0.0002866  loss_rpn_loc: 0.002265  time: 1.0706  data_time: 0.0062  lr: 0.00059827  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:59:19 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 1639  total_loss: 0.2091  loss_cls: 0.03594  loss_box_reg: 0.1086  loss_mask: 0.0579  loss_rpn_cls: 0.0002075  loss_rpn_loc: 0.001437  time: 1.0708  data_time: 0.0060  lr: 0.00057057  max_mem: 4821M\n",
      "\u001b[32m[10/06 10:59:41 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 1659  total_loss: 0.1973  loss_cls: 0.03622  loss_box_reg: 0.1044  loss_mask: 0.05456  loss_rpn_cls: 0.0001622  loss_rpn_loc: 0.001984  time: 1.0711  data_time: 0.0057  lr: 0.00054334  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:00:02 d2.utils.events]: \u001b[0m eta: 0:13:04  iter: 1679  total_loss: 0.2295  loss_cls: 0.0388  loss_box_reg: 0.1262  loss_mask: 0.04729  loss_rpn_cls: 0.0003192  loss_rpn_loc: 0.001957  time: 1.0712  data_time: 0.0063  lr: 0.00051659  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:00:24 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 1699  total_loss: 0.2765  loss_cls: 0.04704  loss_box_reg: 0.1341  loss_mask: 0.04876  loss_rpn_cls: 0.0005986  loss_rpn_loc: 0.00174  time: 1.0713  data_time: 0.0062  lr: 0.00049035  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:00:45 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 1719  total_loss: 0.2003  loss_cls: 0.04146  loss_box_reg: 0.114  loss_mask: 0.05448  loss_rpn_cls: 0.0008249  loss_rpn_loc: 0.002113  time: 1.0714  data_time: 0.0061  lr: 0.00046462  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:01:07 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 1739  total_loss: 0.1881  loss_cls: 0.03646  loss_box_reg: 0.103  loss_mask: 0.04964  loss_rpn_cls: 0.0003987  loss_rpn_loc: 0.002011  time: 1.0714  data_time: 0.0064  lr: 0.00043943  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:01:28 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 1759  total_loss: 0.2184  loss_cls: 0.04078  loss_box_reg: 0.1255  loss_mask: 0.05775  loss_rpn_cls: 0.0004117  loss_rpn_loc: 0.002219  time: 1.0713  data_time: 0.0062  lr: 0.0004148  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:01:50 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 1779  total_loss: 0.2138  loss_cls: 0.04112  loss_box_reg: 0.1149  loss_mask: 0.05431  loss_rpn_cls: 0.0002852  loss_rpn_loc: 0.001802  time: 1.0713  data_time: 0.0059  lr: 0.00039074  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:02:11 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 1799  total_loss: 0.1572  loss_cls: 0.02876  loss_box_reg: 0.08603  loss_mask: 0.03851  loss_rpn_cls: 0.0002137  loss_rpn_loc: 0.001478  time: 1.0712  data_time: 0.0063  lr: 0.00036727  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:02:33 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 1819  total_loss: 0.2337  loss_cls: 0.03718  loss_box_reg: 0.125  loss_mask: 0.04935  loss_rpn_cls: 0.0002049  loss_rpn_loc: 0.001817  time: 1.0713  data_time: 0.0063  lr: 0.00034441  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:02:54 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 1839  total_loss: 0.2241  loss_cls: 0.04037  loss_box_reg: 0.1111  loss_mask: 0.04822  loss_rpn_cls: 0.0003274  loss_rpn_loc: 0.002009  time: 1.0715  data_time: 0.0063  lr: 0.00032216  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:03:15 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 1859  total_loss: 0.1996  loss_cls: 0.03412  loss_box_reg: 0.1111  loss_mask: 0.04856  loss_rpn_cls: 0.0001243  loss_rpn_loc: 0.001948  time: 1.0714  data_time: 0.0063  lr: 0.00030056  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:03:37 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 1879  total_loss: 0.1861  loss_cls: 0.03401  loss_box_reg: 0.09705  loss_mask: 0.0508  loss_rpn_cls: 0.0002371  loss_rpn_loc: 0.001527  time: 1.0715  data_time: 0.0062  lr: 0.0002796  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:03:59 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 1899  total_loss: 0.1769  loss_cls: 0.0377  loss_box_reg: 0.09729  loss_mask: 0.04125  loss_rpn_cls: 0.0003456  loss_rpn_loc: 0.001769  time: 1.0717  data_time: 0.0063  lr: 0.00025931  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:04:21 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 1919  total_loss: 0.1736  loss_cls: 0.02524  loss_box_reg: 0.09792  loss_mask: 0.03925  loss_rpn_cls: 0.0001944  loss_rpn_loc: 0.00191  time: 1.0718  data_time: 0.0063  lr: 0.00023969  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:04:42 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 1939  total_loss: 0.1683  loss_cls: 0.02806  loss_box_reg: 0.09817  loss_mask: 0.04907  loss_rpn_cls: 0.0004437  loss_rpn_loc: 0.001698  time: 1.0717  data_time: 0.0062  lr: 0.00022077  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:05:03 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 1959  total_loss: 0.1576  loss_cls: 0.03295  loss_box_reg: 0.08302  loss_mask: 0.04549  loss_rpn_cls: 0.0001928  loss_rpn_loc: 0.001584  time: 1.0717  data_time: 0.0063  lr: 0.00020255  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:05:25 d2.utils.events]: \u001b[0m eta: 0:07:38  iter: 1979  total_loss: 0.1677  loss_cls: 0.02916  loss_box_reg: 0.07784  loss_mask: 0.04391  loss_rpn_cls: 0.0001162  loss_rpn_loc: 0.001509  time: 1.0718  data_time: 0.0061  lr: 0.00018506  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:05:47 d2.data.datasets.coco]: \u001b[0mLoaded 501 images in COCO format from Data/Valid/Valid.json\n",
      "\u001b[32m[10/06 11:05:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/06 11:05:47 d2.data.common]: \u001b[0mSerializing 501 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/06 11:05:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.25 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/06 11:05:47 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[10/06 11:05:47 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 1999  total_loss: 0.1528  loss_cls: 0.02638  loss_box_reg: 0.09633  loss_mask: 0.0388  loss_rpn_cls: 0.0001292  loss_rpn_loc: 0.001656  time: 1.0719  data_time: 0.0061  lr: 0.00016829  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:06:08 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 2019  total_loss: 0.1765  loss_cls: 0.0309  loss_box_reg: 0.1099  loss_mask: 0.03927  loss_rpn_cls: 0.0004007  loss_rpn_loc: 0.001675  time: 1.0720  data_time: 0.0065  lr: 0.00015226  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:06:30 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 2039  total_loss: 0.2355  loss_cls: 0.03981  loss_box_reg: 0.1181  loss_mask: 0.04929  loss_rpn_cls: 0.0005003  loss_rpn_loc: 0.001823  time: 1.0722  data_time: 0.0062  lr: 0.00013699  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:06:52 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 2059  total_loss: 0.1857  loss_cls: 0.03524  loss_box_reg: 0.09342  loss_mask: 0.04322  loss_rpn_cls: 0.0001892  loss_rpn_loc: 0.001805  time: 1.0722  data_time: 0.0062  lr: 0.00012247  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:07:13 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 2079  total_loss: 0.1574  loss_cls: 0.03764  loss_box_reg: 0.07941  loss_mask: 0.03787  loss_rpn_cls: 0.0003334  loss_rpn_loc: 0.001654  time: 1.0723  data_time: 0.0063  lr: 0.00010873  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:07:35 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 2099  total_loss: 0.2586  loss_cls: 0.04471  loss_box_reg: 0.1254  loss_mask: 0.06002  loss_rpn_cls: 0.0002085  loss_rpn_loc: 0.002048  time: 1.0722  data_time: 0.0062  lr: 9.5778e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:07:56 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 2119  total_loss: 0.1594  loss_cls: 0.0316  loss_box_reg: 0.09771  loss_mask: 0.03722  loss_rpn_cls: 0.0002671  loss_rpn_loc: 0.001739  time: 1.0724  data_time: 0.0061  lr: 8.3612e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:08:18 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 2139  total_loss: 0.1576  loss_cls: 0.03684  loss_box_reg: 0.08819  loss_mask: 0.04693  loss_rpn_cls: 0.0001094  loss_rpn_loc: 0.001746  time: 1.0725  data_time: 0.0061  lr: 7.2245e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:08:40 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 2159  total_loss: 0.1613  loss_cls: 0.03396  loss_box_reg: 0.08991  loss_mask: 0.03932  loss_rpn_cls: 0.0002282  loss_rpn_loc: 0.001896  time: 1.0725  data_time: 0.0062  lr: 6.1686e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:09:01 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 2179  total_loss: 0.1414  loss_cls: 0.02485  loss_box_reg: 0.07794  loss_mask: 0.03397  loss_rpn_cls: 0.0001549  loss_rpn_loc: 0.001482  time: 1.0725  data_time: 0.0063  lr: 5.1941e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:09:23 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 2199  total_loss: 0.1499  loss_cls: 0.02406  loss_box_reg: 0.08046  loss_mask: 0.03968  loss_rpn_cls: 0.0002588  loss_rpn_loc: 0.001685  time: 1.0726  data_time: 0.0061  lr: 4.3017e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:09:44 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 2219  total_loss: 0.2289  loss_cls: 0.04743  loss_box_reg: 0.1209  loss_mask: 0.05734  loss_rpn_cls: 0.0001675  loss_rpn_loc: 0.001774  time: 1.0727  data_time: 0.0062  lr: 3.4921e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:10:06 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 2239  total_loss: 0.1731  loss_cls: 0.03314  loss_box_reg: 0.1005  loss_mask: 0.03975  loss_rpn_cls: 0.0001003  loss_rpn_loc: 0.001549  time: 1.0726  data_time: 0.0065  lr: 2.7657e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:10:27 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 2259  total_loss: 0.1796  loss_cls: 0.03167  loss_box_reg: 0.09338  loss_mask: 0.04662  loss_rpn_cls: 0.0003239  loss_rpn_loc: 0.001826  time: 1.0726  data_time: 0.0059  lr: 2.1231e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:10:49 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 2279  total_loss: 0.1624  loss_cls: 0.02922  loss_box_reg: 0.08727  loss_mask: 0.04117  loss_rpn_cls: 0.0002398  loss_rpn_loc: 0.001203  time: 1.0727  data_time: 0.0060  lr: 1.5647e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:11:10 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 2299  total_loss: 0.2707  loss_cls: 0.04703  loss_box_reg: 0.1273  loss_mask: 0.06444  loss_rpn_cls: 0.000353  loss_rpn_loc: 0.002895  time: 1.0726  data_time: 0.0059  lr: 1.0909e-05  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:11:32 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 2319  total_loss: 0.1966  loss_cls: 0.04163  loss_box_reg: 0.09646  loss_mask: 0.04526  loss_rpn_cls: 0.0002557  loss_rpn_loc: 0.001748  time: 1.0727  data_time: 0.0059  lr: 7.0197e-06  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:11:53 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 2339  total_loss: 0.1649  loss_cls: 0.03102  loss_box_reg: 0.08297  loss_mask: 0.03895  loss_rpn_cls: 0.0002967  loss_rpn_loc: 0.001654  time: 1.0727  data_time: 0.0062  lr: 3.9828e-06  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:12:15 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 2359  total_loss: 0.1723  loss_cls: 0.02974  loss_box_reg: 0.09176  loss_mask: 0.04519  loss_rpn_cls: 0.0001472  loss_rpn_loc: 0.001522  time: 1.0729  data_time: 0.0064  lr: 1.7998e-06  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:12:37 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 2379  total_loss: 0.1588  loss_cls: 0.03392  loss_box_reg: 0.08269  loss_mask: 0.03902  loss_rpn_cls: 0.0002635  loss_rpn_loc: 0.001609  time: 1.0730  data_time: 0.0064  lr: 4.7225e-07  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:12:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2399  total_loss: 0.2073  loss_cls: 0.03747  loss_box_reg: 0.1069  loss_mask: 0.05642  loss_rpn_cls: 0.0003847  loss_rpn_loc: 0.002212  time: 1.0729  data_time: 0.0062  lr: 1.0709e-09  max_mem: 4821M\n",
      "\u001b[32m[10/06 11:12:58 d2.engine.hooks]: \u001b[0mOverall training speed: 2398 iterations in 0:42:52 (1.0729 s / it)\n",
      "\u001b[32m[10/06 11:12:58 d2.engine.hooks]: \u001b[0mTotal training time: 0:42:54 (0:00:01 on hooks)\n",
      "\u001b[32m[10/06 11:12:58 d2.data.datasets.coco]: \u001b[0mLoaded 501 images in COCO format from Data/Valid/Valid.json\n",
      "\u001b[32m[10/06 11:12:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/06 11:12:58 d2.data.common]: \u001b[0mSerializing 501 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/06 11:12:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.25 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/06 11:12:58 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (train_name,)\n",
    "cfg.DATASETS.TEST = (valid_name,)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "\n",
    "\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME =  \"WarmupCosineLR\"\n",
    "cfg.SOLVER.gamma = 0.1\n",
    "# cfg.SOLVER.momentum = 1.0\n",
    "cfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 2400    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = [0,600,1800]        # do not decay learning rate\n",
    "\n",
    "\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 2   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1    # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 400\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "trainer = DefaultTrainer(cfg)\n",
    "\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d553f0bd-f421-42d0-a00d-dc8cfbe970c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_time\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (120,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17712/1335545240.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17712/1335545240.py\u001b[0m in \u001b[0;36mplots\u001b[0;34m(logs_dir)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iteration\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     return gca().plot(\n\u001b[1;32m   3020\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   3022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (120,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "#\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from  matplotlib.pyplot import plot\n",
    "\n",
    "\n",
    "def plots(logs_dir):\n",
    "    path = os.path.join(logs_dir,'metrics.json')\n",
    "    df = pd.read_json(path,lines=True\n",
    "                     )\n",
    "    iteration = df['iteration']\n",
    "    for p in df.keys():\n",
    "        print(len(p))\n",
    "        \n",
    "        plot(p,iteration)\n",
    "        break\n",
    "        if p == \"iteration\":\n",
    "            print('spo')\n",
    "#     x = {\n",
    "#         df['fast_rcnn/cls_accuracy']:df['iteration'],\n",
    "#         df['fast_rcnn/false_negative']: df['iteration'],\n",
    "#         df['fast_rcnn/fg_cls_accuracy']: df['iteration'],\n",
    "        \n",
    "#     }\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "(plots('output'))    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5150b94-47fb-468e-9776-f33acd45e6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.4\n",
      "  latest version: 4.10.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ubuntu/anaconda3/envs/tf2\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.6\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _libgcc_mutex-0.1          |      conda_forge           3 KB  conda-forge\n",
      "    _openmp_mutex-4.5          |            1_gnu          22 KB  conda-forge\n",
      "    libffi-3.4.2               |       h9c3ff4c_4          57 KB  conda-forge\n",
      "    libgcc-ng-11.2.0           |       h1d223b6_9         889 KB  conda-forge\n",
      "    libgomp-11.2.0             |       h1d223b6_9         428 KB  conda-forge\n",
      "    libstdcxx-ng-11.2.0        |       he4da1e4_9         4.2 MB  conda-forge\n",
      "    libzlib-1.2.11             |    h36c2ea0_1013          59 KB  conda-forge\n",
      "    openssl-1.1.1l             |       h7f98852_0         2.1 MB  conda-forge\n",
      "    python-3.6.13              |hb7a2778_2_cpython        38.3 MB  conda-forge\n",
      "    python_abi-3.6             |          2_cp36m           4 KB  conda-forge\n",
      "    sqlite-3.36.0              |       h9cd32fc_2         1.4 MB  conda-forge\n",
      "    tk-8.6.11                  |       h27826a3_1         3.3 MB  conda-forge\n",
      "    zlib-1.2.11                |    h36c2ea0_1013          86 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        50.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge\n",
      "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-1_gnu\n",
      "  ca-certificates    conda-forge/linux-64::ca-certificates-2021.5.30-ha878542_0\n",
      "  certifi            conda-forge/linux-64::certifi-2021.5.30-py36h5fab9bb_0\n",
      "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.36.1-hea4e1c9_2\n",
      "  libffi             conda-forge/linux-64::libffi-3.4.2-h9c3ff4c_4\n",
      "  libgcc-ng          conda-forge/linux-64::libgcc-ng-11.2.0-h1d223b6_9\n",
      "  libgomp            conda-forge/linux-64::libgomp-11.2.0-h1d223b6_9\n",
      "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-11.2.0-he4da1e4_9\n",
      "  libzlib            conda-forge/linux-64::libzlib-1.2.11-h36c2ea0_1013\n",
      "  ncurses            conda-forge/linux-64::ncurses-6.2-h58526e2_4\n",
      "  openssl            conda-forge/linux-64::openssl-1.1.1l-h7f98852_0\n",
      "  pip                conda-forge/noarch::pip-21.2.4-pyhd8ed1ab_0\n",
      "  python             conda-forge/linux-64::python-3.6.13-hb7a2778_2_cpython\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.6-2_cp36m\n",
      "  readline           conda-forge/linux-64::readline-8.1-h46c0cb4_0\n",
      "  setuptools         conda-forge/linux-64::setuptools-49.6.0-py36h5fab9bb_3\n",
      "  sqlite             conda-forge/linux-64::sqlite-3.36.0-h9cd32fc_2\n",
      "  tk                 conda-forge/linux-64::tk-8.6.11-h27826a3_1\n",
      "  wheel              conda-forge/noarch::wheel-0.37.0-pyhd8ed1ab_1\n",
      "  xz                 conda-forge/linux-64::xz-5.2.5-h516909a_1\n",
      "  zlib               conda-forge/linux-64::zlib-1.2.11-h36c2ea0_1013\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "!conda create -n tf2 python=3.6\n",
    "!activate tf2\n",
    "!pip install tf-nightly-gpu-2.0-preview\n",
    "!conda install jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "908b18a7-45bc-461d-947b-252e6aec07f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Found existing installation: tensorboard 2.6.0\n",
      "Uninstalling tensorboard-2.6.0:\n",
      "  Successfully uninstalled tensorboard-2.6.0\n",
      "\u001b[33mWARNING: Skipping tb-nightly as it is not installed.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting tb-nightly\n",
      "  Downloading tb_nightly-2.7.0a20211005-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 14.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (0.14.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (49.6.0.post20210108)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (1.18.5)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (0.37.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (1.41.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (3.17.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from tb-nightly) (1.8.0)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from absl-py>=0.4->tb-nightly) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tb-nightly) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tb-nightly) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tb-nightly) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from markdown>=2.6.8->tb-nightly) (4.6.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly) (3.5.0)\n",
      "Installing collected packages: tb-nightly\n",
      "Successfully installed tb-nightly-2.7.0a20211005\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y tensorboard tb-nightly && pip install tb-nightly  # must have at least tb-nightly==2.5.0a20210316\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33c3e7-ab56-480c-b0a1-8b95bdd7052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"/content/drive/MyDrive/FiberIQ/MyProjects/Output_models/output_bbox_2/model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p37)",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
